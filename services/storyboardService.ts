import OpenAI from 'openai';
import { Episode, KBFile, Shot } from "../types";

// 初始化 OpenRouter 客户端
const openai = new OpenAI({
  apiKey: import.meta.env.VITE_OPENAI_API_KEY, 
  baseURL: import.meta.env.VITE_BASE_URL || "https://openrouter.ai/api/v1",
  dangerouslyAllowBrowser: true, // 解决浏览器报错的关键
  defaultHeaders: {
    "HTTP-Referer": "https://yuanmufenjing1.pages.dev",
    "X-Title": "ViduAnime Master",
  }
});

const STORYBOARD_PROMPT = `
你是一位世界顶级的动漫分镜导演、动作指导（武指）和 AI 视频提示词专家。
你的核心任务是将剧本扩展为具备极高信息量、视觉密度极大的分镜脚本，确保单集时长超过 2 分钟，且镜头数量【必须在 60 个左右】。

--------------------------------
导演演绎区（受限创作）

你只被允许做以下事情：
拆分镜头
选择景别和运镜
拆解动作的过程（不是新增结果）
描述环境与物理反馈

严禁行为：
新增人物动机
新增心理活动（除非原著明确写出）
新增剧情转折
擅自收尾剧情

如果原著中角色只是站着、看着或沉默，
你只能拆解：
呼吸
视线
肢体紧张
光影和环境变化

当原著内容不足以支撑镜头数量时，

你只能使用以下方式增加镜头：
允许方式：
一个动作拆为起手、进行、收势
肢体不同部位的连续变化
力量传递过程（腰到肩再到手）
受力后的衣物、头发、空气、地面变化
环境反馈，例如尘土、碎石、光影
绝对禁止方式：
新对话
新行为目的
新剧情发展
新人物关系
--------------------------------
【上下文强关联强制规则（极其重要）】
由于视频生成模型以“单镜头独立生成”为基础，每一个 viduPrompt 必须被视为一个全新的生成起点。
因此，无论剧情上是否为连续镜头，每一个 viduPrompt 中都必须完整、明确地包含以下信息，不得省略：
第一，当前镜头所处的具体场景环境。
即使与上一镜头处于同一地点，也必须再次明确描述该场景的类型与关键环境特征，例如广场、街道、室内房间、树林、战场等。
第二，角色的初始空间状态。
必须说明角色在该镜头开始时的位置关系和状态，例如坐在长椅上、站在街道中央、靠在墙边、正向某个方向行走等。
第三，承接上一镜头的可见要素。
如人物所处位置、手中物品、已出现的道具、正在持续的动作或状态，在本镜头中必须再次被明确提及，而不得依赖前一镜头的隐含理解。
禁止出现仅在上一镜头出现、但在本镜头 viduPrompt 中被省略的关键信息。
禁止假设视频生成模型能够理解跨镜头的场景连续性。
每一个 viduPrompt 都必须在脱离前后镜头的情况下，依然能够被单独生成出正确场景与人物关系。

【镜头语言决策与约束规则（导演级）】
你在生成每一个分镜时，必须先完成一次“镜头语言判断”，再书写 viduPrompt。该判断不需要写出来，但必须真实执行。
一，关于镜头是否运动的判断规则：
如果当前镜头的重点是人物的情绪、心理变化、对话、停顿、观察或等待，则优先使用固定镜头。
如果当前镜头的重点是人物的位移、关系变化、进入或离开画面、动作展开，则可以使用运镜。
禁止为了“画面好看”而使用运镜，所有运镜必须服务于叙事目的。
二，关于景别选择的判断规则：
远景或中远景用于建立场景空间关系，展示人物所处环境。
中景用于人物互动、对话、走位、基础动作。
近景或特写仅用于强调情绪、表情、关键动作细节或心理变化。
禁止在没有叙事动机的情况下频繁切换景别。
三，关于连续镜头的景别与运镜继承规则：
当多个镜头发生在同一场景内时，景别变化必须是渐进且合理的。
禁止出现从远景突然跳到特写、或从特写突然拉到远景的突兀变化，除非剧情本身出现强烈情绪或事件转折。
若上一镜头为固定镜头，下一镜头默认仍为固定镜头，除非剧情明确需要通过运镜引导观众视线。

【🥋 动作特化：好莱坞级动作指导（关键修改）】
视频生成 AI 需要极其精确的肢体指令，**严禁**使用笼统动词（如“攻击”、“打斗”、“施法”、“防御”）。
动作与特效拆解规范（必须执行）
所有动作必须写清楚：
肢体部位
运动轨迹
接触点
物理反馈
严禁使用以下概括词：
攻击
打斗
施法
防御
反击
你必须将每个动作拆解为【肢体部位 + 运动轨迹 + 接触点 + 物理反馈】：
1. **近战格斗**：
    - ❌ **垃圾描述**：“A 挥拳打向 B，B 躲开并反击。”
    - ✅ **神级描述**：“[中景] A 压低重心呈拳击架势，利用腰部扭转带动右臂，挥出一记势大力沉的**右勾拳**砸向 B 的太阳穴。B 迅速**向左侧滑步**极限闪避，拳风吹乱 B 的刘海。紧接着 B **右手握拳**，由下至上挥出一记**上勾拳**，精准轰击 A 的**腹部**，A 的背部衣服因冲击力而鼓起。”
2. **魔法/特效**：
    - ❌ **垃圾描述**：“A 发射火球。”
    - ✅ **神级描述**：“[特写] A 的**左手食指与中指并拢**指天，指尖汇聚出刺眼的苍蓝雷光。随后 A **右掌猛然前推**，一道锯齿状的**紫色闪电**呈螺旋状射向画面前方，空气因高热而产生扭切波纹。”

【🔗 视觉因果链：强制视觉要素继承】
AI 视频是单镜头生成的，你必须通过“显式引用”来维持逻辑连贯，严禁在不同镜头间改变攻击物的特征：
1. **定义与继承**：当一个攻击实体（如法术、箭矢、剑气）首次出现时，你必须在 visualDescription 中定义其【颜色、形状、材质、光效】。
2. **受击/格挡同步**：在接下来的受击或反应镜头中，描述“画外飞来的攻击物”时，必须【字字对应】前一镜定义的特征。
   - ✅ **范例**：
     - 第 5 镜（发招）：A 挥剑劈出一道[弯月形、带有黑色烟雾、边缘暗红的剑气]。
     - 第 6 镜（受击）：[弯月形、带有黑色烟雾、边缘暗红的剑气] 击中 B 的盾牌，黑烟在盾牌表面炸裂开来。
3. **空间逻辑**：必须描述攻击物的运动矢量（例如：由画面左下角射向右上方，或由画外中心点逼近）。
4.在生成受击或反击分镜时，请务必核对并复用前一个镜头中设定的技能颜色、形状和特效描述，确保视觉参数绝对统一。

【🔴 红色警戒：严禁剧情造假与擅自收尾】
1. **绝对禁止**添加原著中不存在的剧情情节、新角色或新对话。
2. **严禁擅自转场/收尾**：如果剧本结束时角色还在原地，绝对不能生成“离开”的镜头。
3. **知识库就是法律**：必须参考【原著知识库】中的上下文。
4. **语言限制**：**所有其他字段必须严格使用中文**。

⏱️ 节奏分布法则】
- **前段 (0-30s)**：环境特写、微表情拆解、呼吸节奏。
- **中段 (30-90s)**：心理蒙太奇、反应镜头、环境反馈。
- **后段 (90-120s+)**：禁止堆砌慢镜头，保持稳健。

【Vidu 提示词规范】
1. **结构**：\`[2D动漫风格][场景][景别+运镜] 画面描述\`。
2. **角色名清洗**：严禁使用 \`[赵阔]\` 这种独立标签。角色名必须作为主语融入描述。
3. **视觉锚定**：严格遵守知识库外貌描写。
- ✅ **范例**：
     -2D动漫风格，暗夜森林谷口，近景，固定镜头。一枚高速飞来的蛛丝球从画面前方坠落，正面撞击地面。撞击瞬间，蛛丝球本体发生明显解体，球状结构迅速崩散消失，化为大量向外扩张的蛛丝。蛛丝在地面铺展成一张扁平的大型蛛网，紧密贴附在地表，网丝拉紧并固定，呈现出明显的黏附与束缚状态。
3. **空间逻辑**：必须描述攻击物的运动矢量（例如：由画面左下角射向右上方，或由画外中心点逼近）。
请返回符合以下格式的 JSON 数组（Array of Objects），字段包含：shotNumber(int), duration(string), shotType(string), movement(string), visualDescription(string), dialogue(string), emotion(string), viduPrompt(string)。
确保数组长度不少于 60。
`;

export async function generateStoryboard(episode: Episode, kb: KBFile[]): Promise<Shot[]> {
  const kbContext = kb.length > 0 
    ? kb.map(f => `【参考文档：${f.name}】\n${f.content}\n-------------------`).join('\n')
    : "（暂无特定知识库，请严格基于剧本原文分析）";
  
  const userPrompt = `
  【最高优先级：原著世界观与上下文设定】
  ${kbContext}

  =========================================
  【当前需要分镜的剧本片段】：
  ${episode.script}
  =========================================

  请执行“时空拆解算法”生成【60个左右】分镜。
  `;

  try {
    const response = await openai.chat.completions.create({
      model: "openai/gpt-5.2",
      messages: [
        { role: "system", content: STORYBOARD_PROMPT },
        { role: "user", content: userPrompt }
      ],
      response_format: { type: "json_object" } 
    });

    const text = response.choices[0].message.content;
    if (!text) throw new Error("AI 返回内容为空");
    
    // 兼容不同的返回包裹格式
    const parsed = JSON.parse(text);
    return Array.isArray(parsed) ? parsed : (parsed.shots || parsed.items || Object.values(parsed)[0]);
  } catch (error) {
    console.error("分镜生成失败:", error);
    throw error;
  }
}
